{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Неделя 1. Подготовка данных к анализу и построению моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_russian/project_alice/week1_prepare_dataset.ipynb?flush_cache=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.6\n",
      "IPython 7.11.1\n",
      "\n",
      "numpy 1.18.1\n",
      "scipy 1.3.2\n",
      "pandas 0.25.3\n",
      "matplotlib 3.1.1\n",
      "statsmodels 0.10.1\n",
      "sklearn 0.22.1\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 5.3.0-26-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   :\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,statsmodels,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "#pip install tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на один из файлов с данными о посещенных пользователем (номер 31) веб-страницах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10users   4_answer\t\t\t    task1.ipynb\r\n",
      "150users  5_answer\t\t\t    task2.ipynb\r\n",
      "1_answer  capstone_user_identification\t    train_data_10users.csv\r\n",
      "2_answer  capstone_user_identification.zip  train_data_150users.csv\r\n",
      "3_answer  main.py\t\t\t    users.py\r\n",
      "3users\t  __pycache__\t\t\t    week1_prepare_dataset.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поменяйте на свой путь к данным\n",
    "PATH_TO_DATA = '.'\n",
    "user31_data = pd.read_csv(os.path.join(PATH_TO_DATA, \n",
    "                                       '10users/user0031.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-15 08:12:07</td>\n",
       "      <td>fpdownload2.macromedia.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>www.laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-11-15 08:12:18</td>\n",
       "      <td>www.laposte.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                        site\n",
       "0  2013-11-15 08:12:07  fpdownload2.macromedia.com\n",
       "1  2013-11-15 08:12:17                 laposte.net\n",
       "2  2013-11-15 08:12:17             www.laposte.net\n",
       "3  2013-11-15 08:12:17              www.google.com\n",
       "4  2013-11-15 08:12:18             www.laposte.net"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user31_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставим задачу классификации: идентифицировать пользователя по сессии из 10 подряд посещенных сайтов. Объектом в этой задаче будет сессия из 10 сайтов, последовательно посещенных одним и тем же пользователем, признаками – индексы этих 10 сайтов (чуть позже здесь появится \"мешок\" сайтов, подход Bag of Words). Целевым классом будет id пользователя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию prepare_train_set, которая принимает на вход путь к каталогу с csv-файлами path_to_csv_files и параметр session_length – длину сессии, а возвращает 2 объекта:\n",
    "- DataFrame, в котором строки соответствуют уникальным сессиям из session_length сайтов, session_length столбцов – индексам этих session_length сайтов и последний столбец – ID пользователя\n",
    "- частотный словарь сайтов вида {'site_string': [site_id, site_freq]}, например для недавнего игрушечного примера это будет {'vk.com': (1, 2), 'google.com': (2, 2), 'yandex.ru': (3, 3), 'facebook.com': (4, 1)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_sites2(path_to_csv_files, session_length=10):\n",
    "    \"\"\"Returns :\n",
    "    - dictionary of sites were used by users.\n",
    "    \"\"\"\n",
    "    # Vars:\n",
    "\n",
    "    # dictionary of site id's\n",
    "    sites = Counter()\n",
    "    # sessions counter\n",
    "    sessions_counter = 0\n",
    "    # list of user files\n",
    "    fns = glob(path_to_csv_files+\"*\")\n",
    "\n",
    "    # for every file\n",
    "    for f in fns:\n",
    "        # read user data\n",
    "        ud = pd.read_csv(os.path.join(PATH_TO_DATA, f))\n",
    "        # determine sites were visited\n",
    "        sites.update(Counter(ud['site']))\n",
    "#       up session counter\n",
    "        sessions_counter += int(np.ceil(len(ud)/session_length))\n",
    "    # return dictionary with sorted and enumerated sites\n",
    "    result = {}\n",
    "    for i, x in enumerate(sites.most_common()):\n",
    "        result[x[0]] = (i+1, x[1])\n",
    "    return result, sessions_counter, fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def prepare_train_set2(path_to_csv_files, session_length=10):\n",
    "    \"\"\"Returns:\n",
    "    train_data : training table;\n",
    "    sites : dictionary of sites\"\"\"\n",
    "\n",
    "#     Get dictionary of sites\n",
    "    sites, session_counter, fns = get_sites2(path_to_csv_files, session_length)\n",
    "\n",
    "#     Get columns for train table\n",
    "    site_columns = []\n",
    "    for i in range(session_length):\n",
    "        site_columns.append(f\"site{i+1}\")\n",
    "    site_columns.append(\"uid\")\n",
    "\n",
    "#     Training table\n",
    "    train_data = np.zeros(shape=(session_counter, len(site_columns)))\n",
    "#     train_data = csr_matrix((session_counter, len(site_columns)))\n",
    "\n",
    "#     Row counter\n",
    "    active_row = 0\n",
    "\n",
    "#     For every user file\n",
    "    for f in fns:\n",
    "        #         Read user data to DataFrame\n",
    "        d = pd.read_csv(os.path.join(PATH_TO_DATA, f))\n",
    "\n",
    "#         Add site id from dictionary of sites\n",
    "        d['sid'] = d['site'].apply(lambda x: sites[x][0])\n",
    "\n",
    "#         Determine number of new rows:\n",
    "        raws_number = int(np.ceil(len(d)/session_length))\n",
    "\n",
    "#         Write session data to train table:\n",
    "        for i, s in enumerate(d['sid']):\n",
    "            row = active_row + i // session_length\n",
    "            col = i % session_length\n",
    "            train_data[row, col] = s\n",
    "            \n",
    "#         Write user data to train table\n",
    "        for i in range(active_row, active_row+raws_number):\n",
    "            train_data[i, session_length] = int(f[-8:-4])\n",
    "\n",
    "#         Update row counter\n",
    "        active_row += raws_number\n",
    "\n",
    "    return train_data, sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10users\r\n",
      "150users\r\n",
      "3users\r\n",
      "train_data_10users.csv\r\n",
      "train_data_150users.csv\r\n",
      "users.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls | grep users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user0001.csv  user0002.csv  user0003.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./3users/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.6 ms, sys: 0 ns, total: 30.6 ms\n",
      "Wall time: 29.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  2.,  2.,  7.,  2.,  1.,  8.,  5.,  9., 10.,  1.],\n",
       "       [ 3.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 4.,  1.,  2.,  1.,  2.,  1.,  1.,  5., 11.,  4.,  3.],\n",
       "       [ 4.,  1.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.],\n",
       "       [ 3.,  2.,  6.,  6.,  2.,  0.,  0.,  0.,  0.,  0.,  2.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "path = \"3users/\"\n",
    "train_data_toy, _ = prepare_train_set2(path)\n",
    "train_data_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 399 ms, sys: 48.4 ms, total: 448 ms\n",
      "Wall time: 446 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = \"10users/\"\n",
    "train_data_10users, site_freq_10users = prepare_train_set2(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14061"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_10users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4913"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(site_freq_10users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.04 s, sys: 259 ms, total: 4.3 s\n",
      "Wall time: 4.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = \"150users/\"\n",
    "train_data_150users, site_freq_150users = prepare_train_set2(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137019"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_150users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27797"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(site_freq_150users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'www.google.fr www.google.com www.facebook.com apis.google.com s.youtube.com clients1.google.com mail.google.com plus.google.com safebrowsing-cache.google.com www.youtube.com'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "top10 = tuple(itertools.islice(site_freq_150users.items(),10))\n",
    "answer  = \" \".join([x[0] for x in top10])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_answer(i, answer):\n",
    "    with open(f\"{i}_answer\", mode = \"w\") as file:\n",
    "        file.write(str(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_answer(1, 14061)\n",
    "write_answer(2, 4913)\n",
    "write_answer(3, 137019)\n",
    "write_answer(4, 27797)\n",
    "write_answer(5, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_answer\r\n",
      "2_answer\r\n",
      "3_answer\r\n",
      "4_answer\r\n",
      "5_answer\r\n"
     ]
    }
   ],
   "source": [
    "!ls | grep answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_data_10users).to_csv(os.path.join(PATH_TO_DATA, \n",
    "                                       'train_data_10users.csv'), \n",
    "                        index_label='session_id', float_format='%d')\n",
    "pd.DataFrame(train_data_150users).to_csv(os.path.join(PATH_TO_DATA, \n",
    "                                        'train_data_150users.csv'), \n",
    "                         index_label='session_id', float_format='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_data_toy).to_csv(os.path.join(PATH_TO_DATA, \n",
    "                                       'train_data_toy.csv'), \n",
    "                        index_label='session_id', float_format='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
