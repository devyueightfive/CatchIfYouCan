{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Неделя 1. Подготовка данных к анализу и построению моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_russian/project_alice/week1_prepare_dataset.ipynb?flush_cache=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.6\n",
      "IPython 7.11.1\n",
      "\n",
      "numpy 1.18.1\n",
      "scipy 1.3.2\n",
      "pandas 0.25.3\n",
      "matplotlib 3.1.1\n",
      "statsmodels 0.10.1\n",
      "sklearn 0.22.1\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 5.3.0-28-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   :\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,statsmodels,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "#pip install tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на один из файлов с данными о посещенных пользователем (номер 31) веб-страницах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10users\t\t\t\t  X_sparse_10users_s15_w7.pkl\r\n",
      "150users\t\t\t  X_sparse_10users_s5_w5.pkl\r\n",
      "1_answer\t\t\t  X_sparse_10users_s7_w5.pkl\r\n",
      "2_answer\t\t\t  X_sparse_10users_s7_w7.pkl\r\n",
      "3_answer\t\t\t  X_sparse_150users.pkl\r\n",
      "3users\t\t\t\t  X_sparse_150users_s10_w5.pkl\r\n",
      "4_answer\t\t\t  X_sparse_150users_s10_w7.pkl\r\n",
      "5_answer\t\t\t  X_sparse_150users_s15_w10.pkl\r\n",
      "capstone_user_identification.zip  X_sparse_150users_s15_w5.pkl\r\n",
      "__pycache__\t\t\t  X_sparse_150users_s15_w7.pkl\r\n",
      "site_freq_10users.pkl\t\t  X_sparse_150users_s5_w5.pkl\r\n",
      "site_freq_150users.pkl\t\t  X_sparse_150users_s7_w5.pkl\r\n",
      "site_freq_3users.pkl\t\t  X_sparse_150users_s7_w7.pkl\r\n",
      "task1_1.ipynb\t\t\t  y_10users.pkl\r\n",
      "task1_2.ipynb\t\t\t  y_10users_s10_w5.pkl\r\n",
      "task2_1_answer\t\t\t  y_10users_s10_w7.pkl\r\n",
      "task2_1.ipynb\t\t\t  y_10users_s15_w10.pkl\r\n",
      "task2_2_answer\t\t\t  y_10users_s15_w5.pkl\r\n",
      "task2_3_answer\t\t\t  y_10users_s15_w7.pkl\r\n",
      "task2_4_answer\t\t\t  y_10users_s5_w5.pkl\r\n",
      "task2_5_answer\t\t\t  y_10users_s7_w5.pkl\r\n",
      "train_data_10users.csv\t\t  y_10users_s7_w7.pkl\r\n",
      "train_data_150users.csv\t\t  y_150users.pkl\r\n",
      "train_data_toy.csv\t\t  y_150users_s10_w5.pkl\r\n",
      "week1_prepare_dataset.ipynb\t  y_150users_s10_w7.pkl\r\n",
      "week2_analysis_hypotheses.ipynb   y_150users_s15_w10.pkl\r\n",
      "X_sparse_10users.pkl\t\t  y_150users_s15_w5.pkl\r\n",
      "X_sparse_10users_s10_w5.pkl\t  y_150users_s15_w7.pkl\r\n",
      "X_sparse_10users_s10_w7.pkl\t  y_150users_s5_w5.pkl\r\n",
      "X_sparse_10users_s15_w10.pkl\t  y_150users_s7_w5.pkl\r\n",
      "X_sparse_10users_s15_w5.pkl\t  y_150users_s7_w7.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поменяйте на свой путь к данным\n",
    "PATH_TO_DATA = '.'\n",
    "user31_data = pd.read_csv(os.path.join(PATH_TO_DATA, \n",
    "                                       '10users/user0031.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-15 08:12:07</td>\n",
       "      <td>fpdownload2.macromedia.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>www.laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-11-15 08:12:18</td>\n",
       "      <td>www.laposte.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                        site\n",
       "0  2013-11-15 08:12:07  fpdownload2.macromedia.com\n",
       "1  2013-11-15 08:12:17                 laposte.net\n",
       "2  2013-11-15 08:12:17             www.laposte.net\n",
       "3  2013-11-15 08:12:17              www.google.com\n",
       "4  2013-11-15 08:12:18             www.laposte.net"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user31_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставим задачу классификации: идентифицировать пользователя по сессии из 10 подряд посещенных сайтов. Объектом в этой задаче будет сессия из 10 сайтов, последовательно посещенных одним и тем же пользователем, признаками – индексы этих 10 сайтов (чуть позже здесь появится \"мешок\" сайтов, подход Bag of Words). Целевым классом будет id пользователя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию prepare_train_set, которая принимает на вход путь к каталогу с csv-файлами path_to_csv_files и параметр session_length – длину сессии, а возвращает 2 объекта:\n",
    "- DataFrame, в котором строки соответствуют уникальным сессиям из session_length сайтов, session_length столбцов – индексам этих session_length сайтов и последний столбец – ID пользователя\n",
    "- частотный словарь сайтов вида {'site_string': [site_id, site_freq]}, например для недавнего игрушечного примера это будет {'vk.com': (1, 2), 'google.com': (2, 2), 'yandex.ru': (3, 3), 'facebook.com': (4, 1)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def get_sites(path_to_csv_files, session_length=10):\n",
    "    \"\"\"\n",
    "    Returns :\n",
    "    - dictionary of sites used by users;\n",
    "    - sessions counter;\n",
    "    - list of .csv files.\n",
    "    \"\"\"\n",
    "\n",
    "#     ----- Variables:\n",
    "\n",
    "#     Dictionary of sites. Count frequencies of use.\n",
    "    sites = Counter()\n",
    "#     Sessions counter\n",
    "    sessions_counter = 0\n",
    "#     List of .csv files\n",
    "    fns = glob(path_to_csv_files+\"*\")\n",
    "\n",
    "#     ----- Fill `sites` counter. Calculate sessions.\n",
    "\n",
    "#     for every file\n",
    "    for f in fns:\n",
    "#         read user data\n",
    "        ud = pd.read_csv(os.path.join(PATH_TO_DATA, f))\n",
    "#         determine visited sites\n",
    "        sites.update(Counter(ud['site']))\n",
    "#         up session counter\n",
    "        sessions_counter += int(np.ceil(len(ud)/session_length))\n",
    "    \n",
    "    \n",
    "#     ----- Return dictionary with sorted and enumerated sites.\n",
    "    result = {}\n",
    "    for i, x in enumerate(sites.most_common()):\n",
    "        result[x[0]] = (i+1, x[1])\n",
    "    \n",
    "    return result, sessions_counter, fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def prepare_train_set(path_to_csv_files, session_length=10):\n",
    "    \"\"\"Returns:\n",
    "    train_data : training table;\n",
    "    sites : dictionary of sites\"\"\"\n",
    "\n",
    "#     ----- Get dictionary of sites\n",
    "    sites, session_counter, fns = get_sites(path_to_csv_files, session_length)\n",
    "\n",
    "#     ----- Get columns for train table\n",
    "    site_columns = []\n",
    "    for i in range(session_length):\n",
    "        site_columns.append(f\"site{i+1}\")\n",
    "    site_columns.append(\"uid\")\n",
    "\n",
    "#     -----  Construct training table with shape (session_counter, len(site_columns))\n",
    "    train_data = np.zeros(shape=(session_counter, len(site_columns)), dtype = 'int')\n",
    "\n",
    "#     ----- Fill training table\n",
    "#     Variables:\n",
    "#     Row counter\n",
    "    active_row = 0\n",
    "\n",
    "#     For every user file (.csv)\n",
    "    for f in fns:\n",
    "#         Read sites usage data to DataFrame\n",
    "        d = pd.read_csv(os.path.join(PATH_TO_DATA, f))\n",
    "#         Add 'sid' as 'site id' to the table.\n",
    "        d['sid'] = d['site'].apply(lambda x: sites[x][0])\n",
    "#         Determine number of sessions:\n",
    "        raws_number = int(np.ceil(len(d)/session_length))\n",
    "#         Write session data to train table:\n",
    "        for i, s in enumerate(d['sid']):\n",
    "            row = active_row + i // session_length\n",
    "            col = i % session_length\n",
    "            train_data[row, col] = s\n",
    "#         Write user data to train table\n",
    "        for i in range(active_row, active_row+raws_number):\n",
    "            train_data[i, session_length] = int(f[-8:-4])\n",
    "#         Update row counter\n",
    "        active_row += raws_number\n",
    "\n",
    "    return pd.DataFrame(data = train_data, columns = site_columns), sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10users\r\n",
      "150users\r\n",
      "3users\r\n",
      "site_freq_10users.pkl\r\n",
      "site_freq_150users.pkl\r\n",
      "site_freq_3users.pkl\r\n",
      "train_data_10users.csv\r\n",
      "train_data_150users.csv\r\n",
      "X_sparse_10users.pkl\r\n",
      "X_sparse_10users_s10_w5.pkl\r\n",
      "X_sparse_10users_s10_w7.pkl\r\n",
      "X_sparse_10users_s15_w10.pkl\r\n",
      "X_sparse_10users_s15_w5.pkl\r\n",
      "X_sparse_10users_s15_w7.pkl\r\n",
      "X_sparse_10users_s5_w5.pkl\r\n",
      "X_sparse_10users_s7_w5.pkl\r\n",
      "X_sparse_10users_s7_w7.pkl\r\n",
      "X_sparse_150users.pkl\r\n",
      "X_sparse_150users_s10_w5.pkl\r\n",
      "X_sparse_150users_s10_w7.pkl\r\n",
      "X_sparse_150users_s15_w10.pkl\r\n",
      "X_sparse_150users_s15_w5.pkl\r\n",
      "X_sparse_150users_s15_w7.pkl\r\n",
      "X_sparse_150users_s5_w5.pkl\r\n",
      "X_sparse_150users_s7_w5.pkl\r\n",
      "X_sparse_150users_s7_w7.pkl\r\n",
      "y_10users.pkl\r\n",
      "y_10users_s10_w5.pkl\r\n",
      "y_10users_s10_w7.pkl\r\n",
      "y_10users_s15_w10.pkl\r\n",
      "y_10users_s15_w5.pkl\r\n",
      "y_10users_s15_w7.pkl\r\n",
      "y_10users_s5_w5.pkl\r\n",
      "y_10users_s7_w5.pkl\r\n",
      "y_10users_s7_w7.pkl\r\n",
      "y_150users.pkl\r\n",
      "y_150users_s10_w5.pkl\r\n",
      "y_150users_s10_w7.pkl\r\n",
      "y_150users_s15_w10.pkl\r\n",
      "y_150users_s15_w5.pkl\r\n",
      "y_150users_s15_w7.pkl\r\n",
      "y_150users_s5_w5.pkl\r\n",
      "y_150users_s7_w5.pkl\r\n",
      "y_150users_s7_w7.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls | grep users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user0001.csv  user0002.csv  user0003.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./3users/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.34 ms, sys: 8.96 ms, total: 17.3 ms\n",
      "Wall time: 17 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site1  site2  site3  site4  site5  site6  site7  site8  site9  site10  uid\n",
       "0      3      2      2      7      2      1      8      5      9      10    1\n",
       "1      3      1      1      1      0      0      0      0      0       0    1\n",
       "2      4      1      2      1      2      1      1      5     11       4    3\n",
       "3      4      1      2      0      0      0      0      0      0       0    3\n",
       "4      3      2      6      6      2      0      0      0      0       0    2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "path = \"3users/\"\n",
    "train_data_toy, site_freq_3users = prepare_train_set(path)\n",
    "train_data_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 364 ms, sys: 47.9 ms, total: 412 ms\n",
      "Wall time: 411 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = \"10users/\"\n",
    "train_data_10users, site_freq_10users = prepare_train_set(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14061"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_10users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4913"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(site_freq_10users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.86 s, sys: 283 ms, total: 4.14 s\n",
      "Wall time: 4.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = \"150users/\"\n",
    "train_data_150users, site_freq_150users = prepare_train_set(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137019"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_150users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27797"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(site_freq_150users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'www.google.fr www.google.com www.facebook.com apis.google.com s.youtube.com clients1.google.com mail.google.com plus.google.com safebrowsing-cache.google.com www.youtube.com'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "top10 = tuple(itertools.islice(site_freq_150users.items(),10))\n",
    "answer  = \" \".join([x[0] for x in top10])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_answer(i, answer):\n",
    "    with open(f\"{i}_answer\", mode = \"w\") as file:\n",
    "        file.write(str(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_answer(1, 14061)\n",
    "write_answer(2, 4913)\n",
    "write_answer(3, 137019)\n",
    "write_answer(4, 27797)\n",
    "write_answer(5, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_answer\r\n",
      "2_answer\r\n",
      "3_answer\r\n",
      "4_answer\r\n",
      "5_answer\r\n",
      "task2_1_answer\r\n",
      "task2_2_answer\r\n",
      "task2_3_answer\r\n",
      "task2_4_answer\r\n",
      "task2_5_answer\r\n"
     ]
    }
   ],
   "source": [
    "!ls | grep answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_data_10users).to_csv(os.path.join(PATH_TO_DATA, \n",
    "                                       'train_data_10users.csv'), \n",
    "                        index_label='session_id', float_format='%d')\n",
    "pd.DataFrame(train_data_150users).to_csv(os.path.join(PATH_TO_DATA, \n",
    "                                        'train_data_150users.csv'), \n",
    "                         index_label='session_id', float_format='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_data_toy).to_csv(os.path.join(PATH_TO_DATA, \n",
    "                                       'train_data_toy.csv'), \n",
    "                        index_label='session_id', float_format='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA, 'site_freq_3users.pkl'), 'wb') as site_freq_3users_pkl:\n",
    "    pickle.dump(site_freq_3users, site_freq_3users_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'site_freq_10users.pkl'), 'wb') as site_freq_10users_pkl:\n",
    "    pickle.dump(site_freq_10users, site_freq_10users_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'site_freq_150users.pkl'), 'wb') as site_freq_150users_pkl:\n",
    "    pickle.dump(site_freq_150users, site_freq_150users_pkl, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
